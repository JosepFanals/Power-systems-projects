This chapter covers the current status of the topics related to the project, i.e., blockchain and computational methods to solve the power flow problem. It presents a solid explanation regarding the history involved in both subjects with the goal of revealing challenges, which are laid out in Chapter \ref{Challenge}.

\subsection{Blockchain}
\subsubsection{Technical aspects}
Blockchain arrived in the world by the anonymous hand of Satoshi Nakamoto in its famous 2008 white paper \cite{nakamoto2008re}. It was and it is the underlying technology behind Bitcoin, a system meant to allow peer-to-peer cash transactions in a decentralized fashion. In a sense, blockchain is about concatenating data. Data are grouped in blocks and they are in turn linked to the previous sequence of blocks, thus forming a chain, as Figure \ref{fig:block1} displays. 

\begin{figure}[!htb]\centering
    \incfig{blockchain1}
    \caption{Blockchain schematic representation. Own elaboration, adapted from \cite{nofer2017blockchain, zheng2018blockchain}.}
    \label{fig:block1}
\end{figure}
Here metadata refers to the timestamp and the nonce. The former is an indicator of the date of creation associated to such block, whereas the latter stands for "number only used once". Adding a block to the chain is no easy task, as there is a lot of computational power spent in solving a cryptographic puzzle whose solution becomes the aforementioned nonce. Whoever solves first the problem is given a certain amount of Bitcoin. People, or rather, machines who compete in solving such problems are called miners. 

Technically speaking this required mechanism to ensure the addition of blocks is commonly referred to as proof of work. It is based on computing the nonce, which results in a given hash obtained by means of a hash function, in this case, the SHA-256 \cite{nakamoto2008re, gupta2017blockchain}. Simply put a hash is a string of characters with a fixed length responsible for identifying a certain amount of data \cite{di2017blockchain}. In the Bitcoin network, an accepted hash has to respect some requisits. The difficulty of meeting them is adjusted so as to every 10 minutes approximately a new block joins the chain. Modifying past data on the blockchain only becomes feasible if 51\% (or more precisely, the majority) of the computational power is owned by a single entity. This is why Bitcoin and in general blockchain has been thought of as a secure distributed system aimed at avoiding the double-spending problem and immune against Byzantine faults, a common issue in distributed computer systems \cite{sankar2017survey, miller2014anonymous}. 

While Bitcoin was conceived to allow monetary transactions based on the blockchain concept, the truth is that this idea has a much wider application range. This is why many other blockchain projects have emerged during the last decade. Behind Bitcoin, the most relevant platform in terms of market capitalization is Ethereum \cite{ethereum_market}. Ethereum focuses on expanding the blockchain's usage by allowing the creation and deployment of applications, which not only permits trasferring money but also content, property, etc. All of such possible operations are still carried out in a decentralized manner and are practically impossible to corrupt. This is commonly called \textit{code as law}, which stands by the fact that regulations are enforced via code, independently on human intervention \cite{lessig2000code}. 


The smart contracts vocable was coined back in 1994 by Nick Szabo as a way to encapsulate contractual terms into code \cite{szabo1994smart, christidis2016blockchains}. Ethereum is precisely a framework to develop smart contracts written in Solidity. Although it has become the most popular platform to do so, at the point of writing this the highly-anticipated Ethereum 2.0 has still not arrived. Contrarily to the traditional Ethereum network, Ethereum 2.0 is meant to allow substantially more transactions per second and especially at a lower cost \cite{eth2}. In the technical argot, this is mentioned as reducing the gas fees. Since they are extremely expensive, we have decided to build smart contracts on the Matic mainnet, a layer 2 built on top of the Ethereum network \cite{matic_web}. It is visually depicted in Figure \ref{fig:block2}.

\begin{figure}[!htb]\centering
    \incfig{matic1}
    \caption{Scheme of the Matic layer in conjunction with the Ethereum newtork. Own elaboration, adapted from \cite{matic_web}.}
    \label{fig:block2}
\end{figure}
The Matic network is connected to the Ethereum network through the so-called Plasma Checkpoint Nodes, which act as a bridge between both networks. This way multiple blocks in the Matic network are embedded in a single Ethereum block. Contrarily to Bitcoin and Ethereum, Matic is based on the proof of stake consensus algorithm \cite{matic_web}. Miners - who are called validators in the proof of stake scheme - do not compete against each other; instead, the network selects a semi random node to validate the transaction \cite{saleh2021blockchain, gavzi2019proof}. By following this approach, the Matic network becomes a fast low-cost scalable Ethereum extension. 

\subsubsection{Energy-related applications}
Focusing the attention on the energy sector, the German Energy Agency states that the utilization of blockchain can improve the efficiency of the current energy companies' operations, as well as the peer-to-peer energy trading \cite{burger2016blockchain}. This is expected to find its applicability in the energy markets and propel smart grids, among others. The creation of smart contracts is meant to enhance prosumers' participation in the energy market, favoring a decentralized or at least semi-decentralized electric system which influences both generation and consumption. The ideas are still immature, as some projects have been proposed but lack practical implementation \cite{khan2019blockchain, el2020real}. Regulatory, economical, and technological issues are some of the current difficulties.

Overall we are still early in the adoption curve of blockchain in the context of energy, as it is shown in Figure \ref{fig:block3}. Blockchain is expected to be first implemented as a tool to facilitate the integration of the electric vehicle and then proceed to constitute a fundamental technology to allow peer-to-peer energy trading in microgrids \cite{brilliantova2019blockchain,kang2017enabling, khan2019blockchain, pipattanasomporn2018blockchain}. 

\begin{figure}[!htb]\centering
    \incfig{adoption1}
    \caption{Representation of a hypothetical adoption curve of blockchain in the energy sector. Own elaboration, adapted from \cite{faugueras2019state}.}
    \label{fig:block3}
\end{figure}

In fact, the literature mostly focuses on peer-to-peer energy trading. For instance, \cite{vangulick2018blockchain} propose a market design and transaction models to integrate blockchain at the distribution level; \cite{wang2019energy} present a framework to optimally trade energy in smart grids, considering both the day-ahead and the real-time market; \cite{thakur2018peer} assess the impact of coalition formation on microgrids that make use of blockchain to reduce the greenhouse gas emissions; \cite{verma2018enerport} exemplify the implementation of blockchain on Irish microgrids. Generally speaking, such projects have been carried out during the last lustrum, so in all likelihood, we are in the first stages of growth, if not earlier. 

While peer-to-peer energy trading can be regarded as an application with significant affinity due to its decentralized nature and its incorruptibly-centered approach, we believe there are more urgent matters with lesser complexity. One would be to construct design rules with the goal of permitting transactions between prosumers and the DSO, instead of a purely peer-to-peer approach. This explains the semi-decentralized component of this work.

% explain more about this

\subsection{Optimal power flow methods}
The optimal power flow (OPF) is defined as the determination of the most convenient operating point of a given system, all this while satisfying the constraints \cite{neos, ebeed2018optimal}. Sometimes the objective functions could be related to minimizing the total generation cost, while in other situations it could focus on minimizing the active power losses, among other possibilities. In any case, the OPF constitutes an active research field that has evolved drastically since its inception back in 1962 by Carpentier \cite{carpentier1962contribution}. Reviews regarding the classification of algorithms to solve the OPF problem often consider two segments: one has to do with the conventional approach, whereas a more novel one borrows concepts from fields such as artificial intelligence \cite{ebeed2018optimal, frank2012optimal}. These two categories are also called deterministic and non-deterministic, respectively. 

Deterministic methods rely on relatively well-known mathematical tools that have formed the basis of classical programming approaches. Some of them are the Linear Programming method (LP), which linearizes the objective function; the Nonlinear Programming method (NLP), capable of working with nonlinear objective functions and/or nonlinear constraints; the Quadratic Programming (QP) method, which stands as a variation of NLP; Newton's method, based on the Lagrangian and the Hessian matrix; and the Interior Point (IP) method, which was a highly-regarded method two decades ago \cite{momoh1999improved,qiu2009literature}. Due to the nonlinear and nonconvex behavior of the OPF, such deterministic methods are not always acceptable. 

A new trend that has emerged is related to the usage of non-deterministic techniques. Instead of sticking to the equations that define the power flow, they employ heuristics. This is supposed to facilitate the obtention of an optimal solution for both large and small systems, converge rapidly, and overall be more robust than conventional approaches \cite{ebeed2018optimal}. Most of these methods are inspired by natural phenomena, such as the Genetic Algorithm (GA), the Particle Swarm Optimization (PSO), the Graw Wolf Optimizer (GWO), the Differential Evolution (DE), etc. \cite{khamees2016optimal, alrashidi2008survey}.  

The Proper Generalized Decomposition (PGD) that we introduce is a sort of hybrid method, a mix between the two categories. For the most part, it makes use of the power flow equations, but instead of solving the power flow problem each time, it decomposes the variables to speed the calculation process \cite{chinesta2013proper}. It is usually said to combat the curse of dimensionality: a situation where the complexity of the problem grows with an increase in the dimensions. Although it was not first conceptualized as a tool to solve the OPT problem, its characteristics make it suitable for doing so, especially in time-varying scenarios \cite{blanco2017efficient}. In this project, we dedicate a particular chapter to present such methodology.

% also say the PGD is kind of a hybrid method. There are already some hybrid methods.
